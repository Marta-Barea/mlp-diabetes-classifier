# MLP Diabetes Classifier

A simple project to train and evaluate a multilayer perceptron on the Pima Indians Diabetes Dataset using TensorFlow, SciKeras, and Scikit-Learn.

---

# Installation

1. Clone the repo

```bash
git clone https://github.com/yourusername/mlp-diabetes-classifier.git
cd mlp-diabetes-classifier
```

2. Set up the Conda environment

It is included an `environment.yml` for Conda users: 

```bash 
conda env create -f environment.yml
conda activate mlp-diabetes
```

# Dependencies 

- Python 3.7+
- numpy, scikt-learn, tensorflow, scikeras, PyYAML, matplotlib. 

You can also install them with:

```bash
pip install -r requirements.txt
```

# Usage

1. Verify the dataset

The [Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/mathchi/diabetes-data-set) from Kaggle is already included under data/diabetes.csv.

2. Adjust settings

Open `config.yaml`and tweak any values you like (seed, test_size_hyperparameters list, etc.)

3. Run the full pipeline

```bash
python run_all.py
```

This will: 

- Train de MLP with randomized hyperparameter search
- Save the best model to `models/best_mlp.h5`
- Print train/test accuracy and predictions
- Save evaluation plots to `reports/`

# Project Structure

```
mlp-diabetes-classifier/
â”‚
â”œâ”€â”€ config.yaml          # Experiment settings
â”œâ”€â”€ environment.yml      # Conda environment spec
â”œâ”€â”€ requirements.txt     # Pinned pip dependencies (for Docker)
â”œâ”€â”€ docker-compose.yml   # Docker Compose setup
â”œâ”€â”€ Dockerfile           # Image build definition
â”œâ”€â”€ .dockerignore       
â”œâ”€â”€ .gitignore           
â”œâ”€â”€ pytest.ini           
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ diabetes.csv     # Pima Indians Diabetes Dataset
â”‚
â”œâ”€â”€ models/              # (Auto-created) Trained model & params
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures          # (Auto-created) Plots
â”‚
â”œâ”€â”€ tests/               # Test suite
â”‚   â”œâ”€â”€ unit
â”‚   â”œâ”€â”€ integration
â”‚   â””â”€â”€ e2e  
â”‚       
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py        # Loads config.yaml
â”‚   â”œâ”€â”€ data_loader.py   # Reads & splits data
â”‚   â”œâ”€â”€ model_builder.py # Defines the Keras MLP
â”‚   â”œâ”€â”€ train.py         # Hyperparameter search & model saving
â”‚   â””â”€â”€ evaluate.py      # Loads model & prints metrics
â”‚
â””â”€â”€ run_all.py           # Runs train.py then evaluate.py

```

# Dockerized Support

This project is fully containerized for portability and reproducibility.

## Docker Dependencies 

Before using Docker, you need to have the following installed locally on your system:

- [Docker Engine](https://docs.docker.com/get-started/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

âœ… Note: These tools are required only if you want to run the project in a containerized environment. If you're using Conda, Docker is optional.

## How to Run 

To build the image and run the project inside a container:

```bash
docker-compose up --build
```

This will:

- Build the Docker image using the included Dockerfile
- Run the run_all.py pipeline (training + evaluation)
- Save the best trained model in the models/ directory
- Save plots and metrics in the reports/ directory

âœ… Note: Both models/ and reports/ are mounted to your host machine, so your outputs are preserved outside the container.


# Testing

The project includes a complete test suite using [pytest](https://docs.pytest.org/en/stable/). Tests use temporary directories, mock inputs, and validate expected outputs including saved models and plots.

## Run all tests

```bash
pytest
```

This will automatically discover and run:

âœ… Unit tests (tests/unit/)
ğŸ” Integration tests (tests/integration/)
ğŸš€ End-to-End tests (tests/e2e/)

## Run a specific group

```bash 
pytest tests/unit/
```
